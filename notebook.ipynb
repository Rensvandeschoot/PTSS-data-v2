{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back-end code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the files\n",
    "input_file_FT_synergy = Path(\"data/PTSS_Data_Synergy-relabeled.xlsx\")\n",
    "df_synergy = pd.read_excel(input_file_FT_synergy)\n",
    "\n",
    "# Print the number of rows in each file\n",
    "print(\"Number of records in FT_SYNERGY: \", df_synergy.shape[0])\n",
    "\n",
    "# Load the data from the Excel file with catgegories of re-relabeled data\n",
    "file_path = \"data/Table_1.xlsx\"\n",
    "data = pd.read_excel(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## html code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JavaScript and CSS to create the title, styled ToC with indented headers, and dynamically generate ToC entries\n",
    "js_code = \"\"\"\n",
    "<style>\n",
    "    /* Style for the title */\n",
    "    #title {\n",
    "        padding: 20px;\n",
    "        border-bottom: 1px solid #ccc;\n",
    "        text-align: center;\n",
    "        font-family: Arial, sans-serif;\n",
    "        font-size: 24px;\n",
    "        font-weight: bold;\n",
    "    }\n",
    "\n",
    "    /* Style for the authors */\n",
    "    #authors {\n",
    "        padding: 20px;\n",
    "        border-bottom: 1px solid #ccc;\n",
    "        text-align: center;\n",
    "        font-family: Arial, sans-serif;\n",
    "        font-style: italic;\n",
    "    }\n",
    "\n",
    "    /* Style for the ToC container */\n",
    "    #toc {\n",
    "        padding: 20px;\n",
    "        border-bottom: 1px solid #ccc;\n",
    "        font-family: Arial, sans-serif;\n",
    "    }\n",
    "\n",
    "    /* Style for the ToC header */\n",
    "    #toc h2 {\n",
    "        margin-top: 0;\n",
    "    }\n",
    "\n",
    "    /* Style for the ToC list */\n",
    "    #toc ul {\n",
    "        list-style-type: none;\n",
    "        padding-left: 0;\n",
    "    }\n",
    "\n",
    "    /* Style for the ToC list items */\n",
    "    #toc li {\n",
    "        margin-bottom: 5px;\n",
    "    }\n",
    "\n",
    "    /* Style for the ToC links */\n",
    "    #toc a {\n",
    "        text-decoration: none;\n",
    "        color: #007bff;\n",
    "    }\n",
    "\n",
    "    /* Hover effect for the ToC links */\n",
    "    #toc a:hover {\n",
    "        text-decoration: underline;\n",
    "    }\n",
    "\n",
    "    /* Indentation for sub-headers */\n",
    "    .toc-h2 {\n",
    "        margin-left: 20px;\n",
    "    }\n",
    "\n",
    "    .toc-h3 {\n",
    "        margin-left: 40px;\n",
    "    }\n",
    "\n",
    "    .toc-h4 {\n",
    "        margin-left: 60px;\n",
    "    }\n",
    "\n",
    "    .toc-h5 {\n",
    "        margin-left: 80px;\n",
    "    }\n",
    "\n",
    "    .toc-h6 {\n",
    "        margin-left: 100px;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script>\n",
    "<script>\n",
    "    $(document).ready(function() {\n",
    "        // Add a title at the top\n",
    "        $('body').prepend('<div id=\"title\"> Codebook for the re-labeled PTSS dataset</div>');\n",
    "        // Add authors underneath the title\n",
    "        $('#title').after('<div id=\"authors\"> Rens van de Schoot, Bruno Coimbra, Marit Sijbrandij, Rutger Neeleman, Sonja Winter, Mirjam van Zuiden</div>');\n",
    "        \n",
    "        // Create a container for the ToC\n",
    "        $('#authors').after('<div id=\"toc\"><h2>Table of Contents</h2><ul></ul></div>');\n",
    "         \n",
    "        // Function to add ToC entries with appropriate class for indentation\n",
    "        function addToCEntry(text, id, level) {\n",
    "            $('#toc ul').append('<li class=\"toc-' + level + '\"><a href=\"#' + id + '\">' + text + '</a></li>');\n",
    "        }\n",
    "        \n",
    "        // Extract headers and add ToC entries, excluding the title\n",
    "        $('h1, h2, h3, h4, h5, h6').each(function(index) {\n",
    "            var tag = $(this).prop('tagName').toLowerCase();\n",
    "            var text = $(this).text();\n",
    "            var id = 'toc_' + index;\n",
    "            $(this).attr('id', id);\n",
    "            addToCEntry(text, id, tag);\n",
    "        });\n",
    "    });\n",
    "</script>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the JavaScript and CSS code\n",
    "display(HTML(js_code))\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        \"\"\"\n",
    "    <script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script>\n",
    "    <script>\n",
    "        // Function to toggle code visibility\n",
    "        function code_toggle() {\n",
    "            if (code_shown) {\n",
    "                $('.jp-Cell.jp-CodeCell .jp-InputArea').hide();\n",
    "                $('#toggleButton').val('Show Code');\n",
    "            } else {\n",
    "                $('.jp-Cell.jp-CodeCell .jp-InputArea').show();\n",
    "                $('#toggleButton').val('Hide Code');\n",
    "            }\n",
    "            code_shown = !code_shown;\n",
    "        }\n",
    "\n",
    "        $(document).ready(function() {\n",
    "            // Initial state: hide code cells\n",
    "            code_shown = false;\n",
    "            $('.jp-Cell.jp-CodeCell .jp-InputArea').hide();\n",
    "            \n",
    "        });\n",
    "    </script>\n",
    "    <form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This project began with an extensive systematic review of studies estimating latent post-traumatic stress symptom (PTSS) trajectories, aiming to understand diverse patterns of response following traumatic events. Our initial detailed search and screening process, including search queries and logbooks, is documented on the [Open Science Framework project](https://osf.io/4hqk6/).\n",
    "\n",
    "We identified 38 studies relevant studies used for the development of the GRoLTS-checklist, a standardized framework for reporting latent trajectory studies, ensuring methodological rigor and transparency [Van de Schoot et al., 2017](https://doi.org/10.1080/10705511.2016.1247646) and the list of 38 papers is avaialbe at the [OSF](https://osf.io/6vdfk).\n",
    "\n",
    "Building on this groundwork, we focused on reconstructing trajectories to inform prior specifications in a Bayesian LGMM framework [van de Schoot et al., 2018](https://doi.org/10.1080/00273171.2017.1412293). The list of 34 studies used for the Bayesian analyses is available on the [OSF](https://osf.io/h5k2q0); note that we excluded four studies due to stricter criteria for 'traumatic events'. \n",
    "\n",
    "Then, we meticulously de-duplicated the dataset and remained only records with persistent object identifiers (e.g., DOI or PubMed Id), and added OpenAlex identifiers. This version of the dataset was added to the [SYNERGY collection](https://github.com/asreview/synergy-dataset) and is published on Dataverse.NL ([DOI:10.34894/HE6NAQ0](https://dataverse.nl/dataset.xhtml?persistentId=doi:10.34894/HE6NAQ0)). This dataset, with the 38 inclusions but a lower number of total records, serves as a critical resource for benchmark testing of machine learning solutions.\n",
    "\n",
    "More recently, as part of the FORAS project (pre-registered in PROSPERO [CRD42023494027](https://www.crd.york.ac.uk/prospero/display_record.php?RecordID=4940270), we re-evaluated the SYNERGY dataset; see for the updated screening logbook [OSF](https://osf.io/b9gd3/). This involved a comprehensive review and re-application of inclusion criteria, including stricter PTSS definitions, acceptance of treatment studies, and inclusion of studies using PTSD cluster subscores. \n",
    "\n",
    "The dataset contains columns for each of the versions of the labeling decissions. All modifications to the labels are documented in the Table below. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Variables in the dataset\n",
    "The revised dataset, with updated labels, is available for re-use on Dataverse under a permissive license, and contains the following variables.\n",
    "\n",
    "- **MID**: A unique identifier assigned to each record.\n",
    "- **doi**: Digital Object Identifier.\n",
    "- **openalex_id**: Unique identifier from the OpenAlex database.\n",
    "- **title**: Title of the record as identified in the search database.\n",
    "- **title_openalex**: Title as recorded in the OpenAlex database.\n",
    "- **abstract**: Summary of the record's content.\n",
    "- **record_should_have_been_in_synergy**: Indicator of whether the record should have been included in the Synergy dataset.\n",
    "- **TI-AB_original**: Title-Abstract inclusion status in the original dataset.\n",
    "- **FT_original_38**: Full Text inclusion status for the 38 studies initially included.\n",
    "- **FT_original_34**: Full Text inclusion status for the 34 studies after re-evaluation.\n",
    "- **TI-AB-corrected**: Title-Abstract inclusion status after correction in the FORAS project.\n",
    "- **FT-corrected**: Full Text inclusion status after correction in the FORAS project.\n",
    "- **correction_explanation**: Detailed explanation of any corrections made.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table with changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to display each subcategory\n",
    "def display_subcategory(title, df):\n",
    "    df = df.drop(columns=[\"Category\"])\n",
    "    html = df.to_html(index=False, border=0, classes=\"table table-bordered\")\n",
    "    display(\n",
    "        HTML(\n",
    "            f\"\"\"\n",
    "    <h3>{title}</h3>\n",
    "    <style>\n",
    "        .table-bordered {{\n",
    "            border: 1px solid black;\n",
    "            border-collapse: collapse;\n",
    "        }}\n",
    "        .table-bordered th, .table-bordered td {{\n",
    "            border: 1px solid black;\n",
    "            padding: 8px;\n",
    "        }}\n",
    "    </style>\n",
    "    {html}\n",
    "    \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Define subcategory titles\n",
    "subcategories = {\n",
    "    1: \"Re-labeled as FT irrelevant\",\n",
    "    2: \"Re-labelled as FT relevant\",\n",
    "    3: \"In initial data but not in Synergy - added in update\",\n",
    "    4: \"Labeled as TI-AB relevant in update, but not FT\",\n",
    "}\n",
    "\n",
    "# Display each subcategory with a header\n",
    "for key, title in subcategories.items():\n",
    "    subcategory_data = data[data[\"Category\"] == key]\n",
    "    display_subcategory(title, subcategory_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test whether MID/DOI/Open-Alex-Id are unique\n",
    "\n",
    "Ensure all MID values are not null.\n",
    "Ensure the there are no duplicate values for MID/DOI/Open-Alex-Ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find duplicates\n",
    "def find_duplicates(df, column):\n",
    "    duplicates = df[df.duplicated(column, keep=False) & df[column].notnull()]\n",
    "    return duplicates[[\"MID\", column]]\n",
    "\n",
    "\n",
    "# Calculate the number of records without an 'MID' value for the dataset\n",
    "num_records_without_mid_synergy = df_synergy[\"MID\"].isnull().sum()\n",
    "\n",
    "# Calculate the number of duplicate IDs for the dataset\n",
    "num_duplicate_ids_synergy = len(df_synergy[\"MID\"]) - df_synergy[\"MID\"].nunique()\n",
    "\n",
    "# Calculate the number of duplicate DOIs for the dataset, ignoring missing values\n",
    "num_duplicate_doi_synergy = (\n",
    "    len(df_synergy[\"doi\"].dropna()) - df_synergy[\"doi\"].dropna().nunique()\n",
    ")\n",
    "\n",
    "# Calculate the number of duplicate OpenAlex IDs for the dataset, ignoring missing values\n",
    "num_duplicate_openalex_synergy = (\n",
    "    len(df_synergy[\"openalex_id\"].dropna())\n",
    "    - df_synergy[\"openalex_id\"].dropna().nunique()\n",
    ")\n",
    "\n",
    "# Test for MID\n",
    "try:\n",
    "    # Check if there are no records without an identifier in the 'MID' column\n",
    "    assert (\n",
    "        df_synergy[\"MID\"].notnull().all()\n",
    "    ), f\"Test failed: There are {num_records_without_mid_synergy} records without an identifier in the 'MID' column at rows {df_synergy[df_synergy['MID'].isnull()].index.tolist()}.\"\n",
    "\n",
    "    # Check if the identifiers in the 'MID' column are unique\n",
    "    assert (\n",
    "        df_synergy[\"MID\"].nunique() == len(df_synergy[\"MID\"])\n",
    "    ), f\"Test failed: There are {num_duplicate_ids_synergy} duplicate identifiers in the 'MID' column at rows {df_synergy[df_synergy['MID'].duplicated(keep=False)].index.tolist()}.\"\n",
    "\n",
    "    # If the test passes, print the following\n",
    "    print(\n",
    "        \"Test passed: 'MID' column contains no records without an identifier and all identifiers are unique.\"\n",
    "    )\n",
    "except AssertionError as e:\n",
    "    print(e)\n",
    "\n",
    "# Test for DOI\n",
    "try:\n",
    "    # Check if the DOIs are unique, ignoring missing values\n",
    "    assert (\n",
    "        df_synergy[\"doi\"].dropna().nunique() == len(df_synergy[\"doi\"].dropna())\n",
    "    ), f\"Test failed: There are {num_duplicate_doi_synergy} duplicate identifiers in the 'doi' column. Duplicate pairs:\\n{find_duplicates(df_synergy, 'doi')}\"\n",
    "\n",
    "    # If the test passes, print the following\n",
    "    print(\n",
    "        \"Test passed: 'doi' column contains unique identifiers (ignoring missing values).\"\n",
    "    )\n",
    "except AssertionError as e:\n",
    "    print(e)\n",
    "\n",
    "# Test for OpenAlex ID\n",
    "try:\n",
    "    # Check if the OpenAlex IDs are unique, ignoring missing values\n",
    "    assert (\n",
    "        df_synergy[\"openalex_id\"].dropna().nunique()\n",
    "        == len(df_synergy[\"openalex_id\"].dropna())\n",
    "    ), f\"Test failed: There are {num_duplicate_openalex_synergy} duplicate identifiers in the 'openalex_id' column. Duplicate pairs:\\n{find_duplicates(df_synergy, 'openalex_id')}\"\n",
    "\n",
    "    # If the test passes, print the following\n",
    "    print(\n",
    "        \"Test passed: 'openalex_id' column contains unique identifiers (ignoring missing values).\"\n",
    "    )\n",
    "except AssertionError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate missing data and plot for a given dataset\n",
    "def analyze_missing_data(dataset, dataset_name, inclusion_columns):\n",
    "    # Calculate the total number of records with missing values for specified columns\n",
    "    total_missing_data = {\n",
    "        \"DOI Missing\": dataset[\"doi\"].isnull().sum(),\n",
    "        \"OpenAlex ID Missing\": dataset[\"openalex_id\"].isnull().sum(),\n",
    "        \"Both Missing\": dataset[\n",
    "            dataset[\"doi\"].isnull() & dataset[\"openalex_id\"].isnull()\n",
    "        ].shape[0],\n",
    "        \"Title Missing\": dataset[\"title\"].isnull().sum(),\n",
    "        \"Abstract Missing\": dataset[\"abstract\"].isnull().sum(),\n",
    "    }\n",
    "\n",
    "    # Calculate missing data for each inclusion category\n",
    "    missing_data = {category: [] for category in total_missing_data.keys()}\n",
    "\n",
    "    for inclusion_column, positive_label in inclusion_columns.items():\n",
    "        subset = dataset[dataset[inclusion_column] == positive_label]\n",
    "        missing_data[\"DOI Missing\"].append(subset[\"doi\"].isnull().sum())\n",
    "        missing_data[\"OpenAlex ID Missing\"].append(subset[\"openalex_id\"].isnull().sum())\n",
    "        missing_data[\"Both Missing\"].append(\n",
    "            subset[subset[\"doi\"].isnull() & subset[\"openalex_id\"].isnull()].shape[0]\n",
    "        )\n",
    "        missing_data[\"Title Missing\"].append(subset[\"title\"].isnull().sum())\n",
    "        missing_data[\"Abstract Missing\"].append(subset[\"abstract\"].isnull().sum())\n",
    "\n",
    "    # Add the total number of missing records for each category\n",
    "    for category in total_missing_data.keys():\n",
    "        missing_data[category] = [total_missing_data[category]] + missing_data[category]\n",
    "\n",
    "    # Data for plotting\n",
    "    categories = [\n",
    "        \"DOI Missing\",\n",
    "        \"OpenAlex ID Missing\",\n",
    "        \"Both Missing\",\n",
    "        \"Title Missing\",\n",
    "        \"Abstract Missing\",\n",
    "    ]\n",
    "    inclusion_labels = [\"Total\"] + list(inclusion_columns.keys())\n",
    "\n",
    "    # Define the colors for each category\n",
    "    category_colors = [\"#009739\", \"#3E4095\", \"#FFCC29\"]\n",
    "\n",
    "    values = {category: missing_data[category] for category in categories}\n",
    "\n",
    "    # Creating the clustered bar chart with absolute numbers\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    bar_width = 0.2\n",
    "    bar_positions = np.arange(len(categories))\n",
    "\n",
    "    # Plotting bars for each inclusion category\n",
    "    for i, (label, color) in enumerate(zip(inclusion_labels, category_colors)):\n",
    "        plt.bar(\n",
    "            bar_positions + i * bar_width,\n",
    "            [values[category][i] for category in categories],\n",
    "            width=bar_width,\n",
    "            label=label,\n",
    "            color=color,\n",
    "        )\n",
    "\n",
    "    # Adding title and labels for visualization\n",
    "    plt.title(f\"Number of Missing Data in Each Category ({dataset_name})\")\n",
    "    plt.xlabel(\"Missing Data Category\")\n",
    "    plt.ylabel(\"Number of Records\")\n",
    "    plt.xticks(bar_positions + bar_width * (len(inclusion_labels) / 2), categories)\n",
    "    plt.legend(title=\"Inclusion Category\")\n",
    "\n",
    "    # Annotate each bar with its absolute value\n",
    "    for i, label in enumerate(inclusion_labels):\n",
    "        for bar_position, value in zip(\n",
    "            bar_positions + i * bar_width,\n",
    "            [values[category][i] for category in categories],\n",
    "        ):\n",
    "            plt.text(bar_position, value, f\"{value}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    # Display the chart\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# columns to check for inclusion in Synergy dataset with positive labels\n",
    "synergy_inclusions = {\"TI-AB-corrected\": 1, \"FT-corrected\": 1}\n",
    "\n",
    "# call the function for the Synergy dataset\n",
    "analyze_missing_data(df_synergy, \"Synergy\", synergy_inclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of records per classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to analyze\n",
    "columns_to_analyze = [\n",
    "    \"record_should_have_been_in_synergy\",\n",
    "    \"TI-AB_original\",\n",
    "    \"FT_original_38\",\n",
    "    \"FT_original_34\",\n",
    "    \"TI-AB-corrected\",\n",
    "    \"FT-corrected\",\n",
    "]\n",
    "\n",
    "# Calculate the absolute counts of 1s in each column\n",
    "counts_of_ones = df_synergy[columns_to_analyze].apply(lambda col: (col == 1).sum())\n",
    "\n",
    "# Total number of records in the dataframe\n",
    "total_records = len(df_synergy)\n",
    "\n",
    "\n",
    "# Plot the counts in a single bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = counts_of_ones.plot(kind=\"bar\", color=\"#009739\")\n",
    "plt.title(f\"Counts (Total records: {total_records})\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Column\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Add the count at the top of each bar\n",
    "for bar in bars.patches:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        f\"{int(height)}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross tabulation between different classification\n",
    "\n",
    "TI-AB-corrected vs. TI-AB-original: To see how the corrected TI-AB inclusions compare to the original TI-AB inclusions.\n",
    "\n",
    "FT-corrected vs. FT-original_38: To compare the corrected FT inclusions to the original FT inclusions from subset 38.\n",
    "\n",
    "FT-corrected vs. FT-original_34: To compare the corrected FT inclusions to the original FT inclusions from subset 34.\n",
    "\n",
    "TI-AB-corrected vs. FT-corrected: To see the relationship between TI-AB and FT inclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstabulation between TI-AB-corrected and FT-corrected\n",
    "\n",
    "# cross tabulation function\n",
    "\n",
    "\n",
    "def display_crosstab(crosstab, row_label, col_label):\n",
    "    # Convert the crosstab to a list of lists for tabulation\n",
    "    crosstab_data = crosstab.reset_index().values.tolist()\n",
    "\n",
    "    # Get headers for the table\n",
    "    headers = [row_label + \" \\\\ \" + col_label] + crosstab.columns.tolist()\n",
    "\n",
    "    # Generate HTML table\n",
    "    html_crosstab = tabulate(\n",
    "        crosstab_data,\n",
    "        headers=headers,\n",
    "        tablefmt=\"html\",\n",
    "        numalign=\"right\",\n",
    "        stralign=\"center\",\n",
    "    )\n",
    "\n",
    "    # Display HTML table in Jupyter Notebook\n",
    "    display(HTML(html_crosstab))\n",
    "\n",
    "\n",
    "# Generate and display additional crosstabs for Synergy data\n",
    "additional_crosstabs = [\n",
    "    (\n",
    "        pd.crosstab(\n",
    "            df_synergy[\"TI-AB-corrected\"],\n",
    "            df_synergy[\"TI-AB_original\"],\n",
    "            margins=True,\n",
    "            dropna=False,\n",
    "        ),\n",
    "        \"TI-AB-corrected\",\n",
    "        \"TI-AB_original\",\n",
    "    ),\n",
    "    (\n",
    "        pd.crosstab(\n",
    "            df_synergy[\"FT-corrected\"],\n",
    "            df_synergy[\"FT_original_38\"],\n",
    "            margins=True,\n",
    "            dropna=False,\n",
    "        ),\n",
    "        \"FT-corrected\",\n",
    "        \"FT_original_38\",\n",
    "    ),\n",
    "    (\n",
    "        pd.crosstab(\n",
    "            df_synergy[\"FT-corrected\"],\n",
    "            df_synergy[\"FT_original_34\"],\n",
    "            margins=True,\n",
    "            dropna=False,\n",
    "        ),\n",
    "        \"FT-corrected\",\n",
    "        \"FT_original_34\",\n",
    "    ),\n",
    "    (\n",
    "        pd.crosstab(\n",
    "            df_synergy[\"TI-AB-corrected\"],\n",
    "            df_synergy[\"FT-corrected\"],\n",
    "            margins=True,\n",
    "            dropna=False,\n",
    "        ),\n",
    "        \"TI-AB-corrected\",\n",
    "        \"FT-corrected\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "for crosstab, row_label, col_label in additional_crosstabs:\n",
    "    display_crosstab(crosstab, row_label, col_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of inclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autopct_format(values):\n",
    "    def inner_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct * total / 100.0))\n",
    "        return \"{v:d} ({p:.1f}%)\".format(v=val, p=pct)\n",
    "\n",
    "    return inner_autopct\n",
    "\n",
    "\n",
    "# Get value counts for Synergy TI-AB and FT records\n",
    "synergy_tiab_records = df_synergy[\"TI-AB-corrected\"].value_counts()\n",
    "synergy_ft_records = df_synergy[\"FT-corrected\"].value_counts()\n",
    "\n",
    "# Increase figure size for better readability\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Adjust subplot layout\n",
    "plt.subplots_adjust(right=0.85)\n",
    "\n",
    "# Plot Synergy TI-AB pie chart\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pie(\n",
    "    synergy_tiab_records,\n",
    "    colors=[\"#FFD700\", \"#009739\"],\n",
    "    autopct=autopct_format(synergy_tiab_records),\n",
    ")\n",
    "plt.title(f\"Synergy TI-AB Corrected\\nTotal: {synergy_tiab_records.sum()}\")\n",
    "\n",
    "# Plot Synergy FT pie chart\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(\n",
    "    synergy_ft_records,\n",
    "    colors=[\"#FFD700\", \"#009739\"],\n",
    "    autopct=autopct_format(synergy_ft_records),\n",
    ")\n",
    "plt.title(f\"Synergy FT Corrected\\nTotal: {synergy_ft_records.sum()}\")\n",
    "\n",
    "# Enhance legend placement\n",
    "plt.legend(\n",
    "    [\"Excluded\", \"Included\"], loc=\"center left\", bbox_to_anchor=(1, 0.5), frameon=False\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funding\n",
    "The project was funded by the Dutch Research Council under grant no. [406.22.GO.048](https://app.dimensions.ai/details/grant/grant.13726450). \n",
    "\n",
    "# Reference List\n",
    "\n",
    "- van de Schoot, R., Sijbrandij, M., Winter, S. D., Depaoli, S., & Vermunt, J. K. (2017). The GRoLTS-Checklist: Guidelines for Reporting on Latent Trajectory Studies. *Structural Equation Modeling: A Multidisciplinary Journal, 24*(3), 451-467. https://doi.org/10.1080/10705511.2016.1247646\n",
    "- van de Schoot, R., Winter, S. D., Ryan, O., Zondervan-Zwijnenburg, M., & Depaoli, S. (2018). A Systematic Review of Bayesian Latent Growth Mixture Models in Psychology: Modelling Substantial Heterogeneity. *Multivariate Behavioral Research, 53*(4), 479-507. https://doi.org/10.1080/00273171.2017.1412293"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
